# CIFAKE: Explainable Deep Learning for Classifying Real and AI-Generated Images Using CNN and 3D-CNN

## ğŸ“˜ Abstract
Artificial intelligence has advanced to a point where synthetic images created by GANs and diffusion models are extremely realistic, making real vs fake image detection challenging.  
This paper evaluates two models â€” **CNN** and **3Dâ€‘CNN** â€” on the **CIFAKE dataset** (120,000 balanced images).  
Explainable AI methods such as **LIME** and **Gradâ€‘CAM** are used for transparency.

**Results:**  
- CNN â†’ **95.69% accuracy**, **98.00% recall**  
- 3Dâ€‘CNN â†’ **96.62% accuracy**, **95.97% precision**, **97.33% recall**, **96.64% F1-score**  

Both models perform well, but 3Dâ€‘CNN achieves superior robustness.

---

## 1. Introduction
Generative models like **GANs**, **StyleGAN**, and **Stable Diffusion** now produce images nearly indistinguishable from real images. This raises concerns in:

- Misinformation  
- Forgery  
- Identity fraud  
- Digital forensics  
- Media manipulation  

Traditional detection methods fail because synthetic images replicate natural lighting, depth, and texture.

Deep Learning (CNNs, Transformers, Hybrid Models) is now widely used to detect such fakes, requiring large balanced datasets and strong generalization ability.

The **CIFAKE dataset**, consisting of **60k real + 60k synthetic images**, provides a standardized benchmark for evaluating detection systems.

---

## 2. Literature Review
A summarized comparison from prior work:

| Author | Dataset | Model | Accuracy | Limitations |
|--------|---------|--------|----------|-------------|
| Bird et al. | CIFAKE | CNN + XAI | 92.98% | No cross-dataset evaluation |
| Epstein et al. | 570k images | Online model w/ CutMix | 99.2% | Sensitive to generator architecture |
| Baraheem et al. | 24k | VGG, DenseNet, EfficientNet | 100% | Misclassifies GAN images with sharp textures |
| Saskoro et al. | 500k | Gated CNN | 96% | Dependent on dataset diversity |
| Rodriguez et al. | 1,252 | CNN on PRNU/ELA | >95% | Works only on JPEG |
| Our Work | CIFAKE | CNN & 3Dâ€‘CNN | **96.62%** | Higher training cost for 3D-CNN |

---

## 3. Methodology

### 3.1 Dataset Description
According to page 2 of the paper:  
îˆ€fileciteîˆ‚turn1file0îˆ

| Split | REAL | FAKE | Total |
|--------|--------|--------|--------|
| Training | 45,000 | 45,000 | 90,000 |
| Validation | 5,000 | 5,000 | 10,000 |
| Testing | 10,000 | 10,000 | 20,000 |
| **Total** | **60,000** | **60,000** | **120,000** |

The dataset originally contained 120k images but was expanded through preprocessing (next section).

---

## 3.2 Image Preprocessing
Each image was transformed into **6 additional versions**:

- Green channel extraction  
- CLAHE  
- Gaussian blur  
- Grayscale  
- Canny edge detection  
- Sobel gradient magnitude  

â¡ Total Training Images â†’ **600,000**  
â¡ Validation Images â†’ **60,000**  
â¡ Test Images â†’ **120,000**

Fig. 1 (page 2) shows sample preprocessing outputs.  
îˆ€fileciteîˆ‚turn1file0îˆ

---

## 3.3 Image Augmentation
Used to reduce overfitting:

- Random rotation (Â±20Â°)  
- Horizontal/vertical flip  
- Zoom (80â€“120%)  
- Translation (10%)  
- Contrast shift (0.2)

Augmentation was applied **per batch**, improving generalization.

---

## 3.4 CNN Model Architecture
(According to Table III, page 3)  
îˆ€fileciteîˆ‚turn1file0îˆ

5 convolutional blocks:

- 2Ã—Conv2D (3Ã—3), BatchNorm, ReLU  
- MaxPooling  
- Dropout (0.2 â†’ 0.5)  
- Filters: 32 â†’ 64 â†’ 128 â†’ 256 â†’ 512  
- Global Average Pooling  
- Dense + Sigmoid  

---

## 3.5 3Dâ€‘CNN Architecture
(According to Table IV, page 3)  
îˆ€fileciteîˆ‚turn1file0îˆ

Uses spatiotemporal kernels (3Ã—3Ã—3) to capture variability across stacked image channels.

- 5 blocks of Conv3D + BatchNorm  
- MaxPool3D with asymmetric pooling  
- Dropout (0.2 â†’ 0.5)  
- Global Average Pool3D  
- Dense + Sigmoid  

---

## 3.6 Loss Function & Optimization
Binary Cross-Entropy:

\[
L = - rac{1}{N} \sum_{i=1}^{N} [y_i \log(\hat y_i) + (1-y_i) \log(1-\hat y_i)]
\]

Optimizers:

| Model | Learning Rate |
|-------|----------------|
| CNN | 1eâ€‘5 |
| 3Dâ€‘CNN | 1eâ€‘4 |

Early stopping used for best validation loss.

---

## 4. Results

### 4.1 Model Comparison
From Table V (page 4):  
îˆ€fileciteîˆ‚turn1file0îˆ

| Model | Accuracy | Precision | Recall | F1â€‘Score |
|-------|-----------|-----------|---------|-----------|
| CNN | 95.69% | 93.67% | 98.00% | 95.79% |
| **3D-CNN** | **96.62%** | **95.97%** | **97.33%** | **96.64%** |

â¡ **3Dâ€‘CNN is the best-performing model**

---

### 4.2 Confusion Matrix (3Dâ€‘CNN)
From Table VI:  
îˆ€fileciteîˆ‚turn1file0îˆ

| True / Predicted | FAKE (0) | REAL (1) |
|------------------|----------|----------|
| **FAKE** | 9,591 | 409 |
| **REAL** | 267 | 9,733 |

Misclassification:

- 409 fake images predicted as real  
- 267 real images predicted as fake  

---

### 4.3 Gradâ€‘CAM Visualisation
(See Fig. 3, page 5)  
îˆ€fileciteîˆ‚turn1file0îˆ

Observations:

- REAL images â†’ focused activation on meaningful object areas  
- FAKE images â†’ diffuse activation, irregular textures  
- Model detects **synthetic artifacts**, not object semantics  

---

### 4.4 LIME Visualisation
(See Fig. 4, page 5)  
îˆ€fileciteîˆ‚turn1file0îˆ

- REAL â†’ continuous contours highlighted  
- FAKE â†’ fragmented, inconsistent patches  
- Confirms 3Dâ€‘CNNâ€™s robustness in finding anomalies.

---

## 5. Comparison With Previous Works
From Table VII (page 6):  
îˆ€fileciteîˆ‚turn1file0îˆ

| Method | Accuracy |
|--------|----------|
| Bird et al. | 92.98% |
| Epstein et al. (CutMix) | 99.2% |
| Baraheem et al. | 100% |
| Saskoro et al. | 96% |
| **Our CNN** | **95.69%** |
| **Our 3Dâ€‘CNN** | **96.62%** |

Our models provide:

- High accuracy  
- Full explainability  
- Balanced real vs fake dataset  
- Stronger generalization than basic CNN baselines  

---

## 6. Conclusion

This research provides a complete deep-learning pipeline using **CNN** and **3Dâ€‘CNN** for distinguishing real vs AI-generated images on the CIFAKE dataset.

- Preprocessing & augmentation created robust feature variety  
- CNN achieved strong results  
- **3Dâ€‘CNN outperformed all with 96.62% accuracy**  
- XAI techniques (Gradâ€‘CAM & LIME) improved interpretability  

Future improvements:

- Use transformers for deeper global understanding  
- Add SHAP explainability  
- Test on newer diffusion-model outputs  
- Deploy lightweight real-time detectors

---

``
@inproceedings{hosen2025cifake,
  title={CIFAKE: Explainable Deep Learning for Classifying Real and AI-Generated Images Using CNN and 3D-CNN},
  author={Hosen, Md. Hamid and Asif, Mikdad Mohammad and Uddin, Altaf and Chowdhury, Rituparna and Bhottacharjee, Pappuraj and Saha, Arnob},
  booktitle={2025 IEEE International Conference on Biomedical Engineering, Computer and Information Technology for Health (BECITHCON)},
  year={2025},
  organization={IEEE},
  address={Dhaka, Bangladesh}
}
```
